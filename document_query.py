#!/usr/bin/env python3
"""
ë¬¸ì„œ ì§ˆì˜ í”„ë¡œê·¸ë¨

ë²¡í„°ìŠ¤í† ì–´ì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³  LLMì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ëŒ€í™”í˜• í”„ë¡œê·¸ë¨
"""

import os
import sys

from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_ollama import OllamaLLM

from config import (
    EMBEDDING_MODEL_NAME,
    VECTORSTORE_PATH,
    OLLAMA_BASE_URL,
    OLLAMA_MODEL,
    RETRIEVAL_K,
    USE_MMR,
    MMR_FETCH_K,
    MMR_K,
    MMR_LAMBDA,
    NORMALIZE_EMBEDDINGS,
    USE_HYBRID_SEARCH,
    BM25_TOP_K,
    DENSE_TOP_K,
    RRF_TOP_K,
    RRF_CONSTANT,
    USE_RERANKER,
    RERANKER_MODEL,
    RERANKER_TOP_K,
    PROMPT_TEMPLATE,
)


def create_bm25_retriever(vectorstore: FAISS):
    """
    BM25 ê¸°ë°˜ Sparse Retrieverë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        vectorstore: FAISS ë²¡í„°ìŠ¤í† ì–´ (ë¬¸ì„œ ë¡œë“œìš©)

    Returns:
        BM25Retriever: BM25 ê²€ìƒ‰ê¸°
    """
    from rank_bm25 import BM25Okapi

    # FAISSì—ì„œ ëª¨ë“  ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
    all_docs = vectorstore.docstore._dict.values()
    all_docs = list(all_docs)

    # ë¬¸ì„œ í…ìŠ¤íŠ¸ë¥¼ í† í°í™” (ê°„ë‹¨í•œ ê³µë°± ê¸°ë°˜)
    tokenized_docs = [doc.page_content.split() for doc in all_docs]

    # BM25 ì¸ë±ìŠ¤ ìƒì„±
    bm25 = BM25Okapi(tokenized_docs)

    print(f"âœ… BM25 ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ (ë¬¸ì„œ {len(all_docs)}ê°œ)")

    # BM25 ê²€ìƒ‰ í•¨ìˆ˜ ë˜í¼
    class BM25Retriever:
        def __init__(self, bm25_index, documents):
            self.bm25 = bm25_index
            self.documents = documents

        def invoke(self, query: str, top_k: int = 50):
            """ì§ˆë¬¸ì— ëŒ€í•´ BM25ë¡œ ìƒìœ„ ë¬¸ì„œ ë°˜í™˜"""
            tokenized_query = query.split()
            scores = self.bm25.get_scores(tokenized_query)

            # ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
            scored_docs = list(zip(self.documents, scores))
            scored_docs.sort(key=lambda x: x[1], reverse=True)

            # ìƒìœ„ top_kê°œ ë°˜í™˜
            top_docs = [doc for doc, score in scored_docs[:top_k]]
            return top_docs

    return BM25Retriever(bm25, all_docs)


def load_vectorstore() -> FAISS:
    """
    ì €ì¥ëœ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.

    Returns:
        FAISS: ë¡œë“œëœ ë²¡í„°ìŠ¤í† ì–´
    """
    print(f"ğŸ“‚ ë²¡í„°ìŠ¤í† ì–´ ë¡œë”© ì¤‘: {VECTORSTORE_PATH}")

    if not os.path.exists(VECTORSTORE_PATH):
        print(f"âŒ ì˜¤ë¥˜: ë²¡í„°ìŠ¤í† ì–´ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {VECTORSTORE_PATH}")
        print(f"â„¹ï¸  ë¨¼ì € document_register.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ë¬¸ì„œë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”.")
        sys.exit(1)

    # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” (ë“±ë¡ ì‹œì™€ ë™ì¼í•œ ëª¨ë¸ ì‚¬ìš©)
    embeddings = HuggingFaceEmbeddings(
        model_name=EMBEDDING_MODEL_NAME,
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': NORMALIZE_EMBEDDINGS}
    )

    # ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ (FAISS)
    vectorstore = FAISS.load_local(
        VECTORSTORE_PATH,
        embeddings,
        allow_dangerous_deserialization=True  # ë¡œì»¬ íŒŒì¼ ì‹ ë¢°
    )

    print(f"âœ… ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì™„ë£Œ (FAISS IndexFlatIP)")

    return vectorstore


def reciprocal_rank_fusion(bm25_docs, dense_docs, top_k: int = 20, k: int = 60):
    """
    RRF(Reciprocal Rank Fusion)ë¥¼ ì‚¬ìš©í•˜ì—¬ BM25ì™€ Dense ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìœµí•©í•©ë‹ˆë‹¤.

    Args:
        bm25_docs: BM25 ê²€ìƒ‰ ê²°ê³¼ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        dense_docs: Dense(FAISS) ê²€ìƒ‰ ê²°ê³¼ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        top_k: ìµœì¢… ë°˜í™˜í•  ë¬¸ì„œ ê°œìˆ˜
        k: RRF ìƒìˆ˜ (ì¼ë°˜ì ìœ¼ë¡œ 60)

    Returns:
        list: RRFë¡œ ìœµí•©ëœ ìƒìœ„ ë¬¸ì„œë“¤
    """
    from collections import defaultdict

    # ë¬¸ì„œë³„ RRF ì ìˆ˜ ê³„ì‚°
    rrf_scores = defaultdict(float)

    # BM25 ê²°ê³¼ì—ì„œ RRF ì ìˆ˜ ê³„ì‚°
    for rank, doc in enumerate(bm25_docs, start=1):
        doc_id = id(doc)  # ë¬¸ì„œ ê³ ìœ  ID
        rrf_scores[doc_id] += 1.0 / (k + rank)

    # Dense ê²°ê³¼ì—ì„œ RRF ì ìˆ˜ ê³„ì‚°
    for rank, doc in enumerate(dense_docs, start=1):
        doc_id = id(doc)
        rrf_scores[doc_id] += 1.0 / (k + rank)

    # ëª¨ë“  ê³ ìœ  ë¬¸ì„œ ìˆ˜ì§‘ (ì¤‘ë³µ ì œê±°)
    all_docs = {}
    for doc in bm25_docs + dense_docs:
        all_docs[id(doc)] = doc

    # RRF ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
    sorted_docs = sorted(
        all_docs.items(),
        key=lambda x: rrf_scores[x[0]],
        reverse=True
    )

    # ìƒìœ„ top_kê°œ ë°˜í™˜
    top_docs = [doc for doc_id, doc in sorted_docs[:top_k]]

    print(f"ğŸ”€ RRF ìœµí•© ì™„ë£Œ:")
    print(f"   - BM25: {len(bm25_docs)}ê°œ")
    print(f"   - Dense: {len(dense_docs)}ê°œ")
    print(f"   - ê³ ìœ  ë¬¸ì„œ: {len(all_docs)}ê°œ")
    print(f"   - ìµœì¢… ì„ íƒ: {len(top_docs)}ê°œ")

    return top_docs


def rerank_documents(query: str, documents, top_k: int = 5):
    """
    Cross-Encoderë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œë¥¼ ì¬ì •ë ¬í•©ë‹ˆë‹¤.

    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        documents: ì¬ì •ë ¬í•  ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        top_k: ë°˜í™˜í•  ìƒìœ„ ë¬¸ì„œ ê°œìˆ˜

    Returns:
        list: ì¬ì •ë ¬ëœ ìƒìœ„ ë¬¸ì„œë“¤
    """
    from sentence_transformers import CrossEncoder

    # Cross-Encoder ëª¨ë¸ ë¡œë“œ (ìºì‹±ë¨)
    if not hasattr(rerank_documents, 'model'):
        print(f"ğŸ”§ Re-ranker ëª¨ë¸ ë¡œë”© ì¤‘: {RERANKER_MODEL}")
        rerank_documents.model = CrossEncoder(RERANKER_MODEL, max_length=512)
        print(f"âœ… Re-ranker ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

    model = rerank_documents.model

    # ë¬¸ì„œì™€ ì§ˆë¬¸ ìŒ ìƒì„±
    pairs = [[query, doc.page_content] for doc in documents]

    # ì ìˆ˜ ê³„ì‚°
    scores = model.predict(pairs)

    # ì ìˆ˜ ê¸°ì¤€ ì •ë ¬ (ë‚´ë¦¼ì°¨ìˆœ)
    scored_docs = list(zip(documents, scores))
    scored_docs.sort(key=lambda x: x[1], reverse=True)

    # ìƒìœ„ top_kê°œ ë°˜í™˜
    top_docs = [doc for doc, score in scored_docs[:top_k]]

    print(f"ğŸ”„ Re-ranking ì™„ë£Œ: {len(documents)}ê°œ â†’ {len(top_docs)}ê°œ (ìƒìœ„ {top_k}ê°œ)")
    for i, (doc, score) in enumerate(scored_docs[:top_k], 1):
        source = doc.metadata.get('source', 'Unknown')
        print(f"   [{i}] Score: {score:.4f} | {source}")

    return top_docs


def setup_qa_chain(vectorstore: FAISS, bm25_retriever=None):
    """
    QA ì²´ì¸ì„ ì„¤ì •í•©ë‹ˆë‹¤.
    3-Stage Retrieval: Hybrid Search (BM25 + FAISS) â†’ RRF â†’ Re-ranking

    Args:
        vectorstore: ë²¡í„°ìŠ¤í† ì–´
        bm25_retriever: BM25 ê²€ìƒ‰ê¸° (í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ìš©, optional)

    Returns:
        tuple: (retriever, qa_chain)
    """
    print(f"ğŸ”§ LLM ì´ˆê¸°í™” ì¤‘: {OLLAMA_MODEL}")
    print(f"â„¹ï¸  Ollamaê°€ ì‹¤í–‰ ì¤‘ì´ê³  {OLLAMA_MODEL} ëª¨ë¸ì´ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
    print(f"â„¹ï¸  OLLAMA_BASE_URL: {OLLAMA_BASE_URL}")

    # Ollama LLM ì´ˆê¸°í™”
    try:
        llm = OllamaLLM(
            model=OLLAMA_MODEL,
            base_url=OLLAMA_BASE_URL,
            temperature=0.1,  # ë‚®ì€ temperatureë¡œ ì¼ê´€ì„± ìˆëŠ” ë‹µë³€ ìƒì„±
        )
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
        _ = llm.invoke("test")
        print(f"âœ… LLM ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        print(f"\nâ„¹ï¸  Ollama ì„¤ì • í™•ì¸:")
        print(f"  1. Ollamaê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸: ollama serve")
        print(f"  2. ëª¨ë¸ì´ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸: ollama list")
        print(f"  3. ëª¨ë¸ ì„¤ì¹˜: ollama pull {OLLAMA_MODEL}")
        sys.exit(1)

    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì • (configì—ì„œ ê°€ì ¸ì˜´)
    prompt = PromptTemplate(
        template=PROMPT_TEMPLATE,
        input_variables=["context", "question"]
    )

    # Dense Retriever ì„¤ì • (FAISS)
    if USE_HYBRID_SEARCH:
        print(f"ğŸ” Stage 1 - Hybrid Search ì„¤ì •")
        print(f"   - Dense (FAISS): {DENSE_TOP_K}ê°œ")
        print(f"   - Sparse (BM25): {BM25_TOP_K}ê°œ")
        print(f"   - RRF ìœµí•© í›„: {RRF_TOP_K}ê°œ")

        # FAISS Dense retriever
        dense_retriever = vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={"k": DENSE_TOP_K}
        )
    elif USE_MMR:
        print(f"ğŸ” Stage 1 - Retriever ì„¤ì •: MMR (ë‹¤ì–‘ì„± í™•ë³´)")
        print(f"   - k={MMR_K}, fetch_k={MMR_FETCH_K}, lambda={MMR_LAMBDA}")
        dense_retriever = vectorstore.as_retriever(
            search_type="mmr",
            search_kwargs={
                "k": MMR_K,
                "fetch_k": MMR_FETCH_K,
                "lambda_mult": MMR_LAMBDA
            }
        )
    else:
        print(f"ğŸ” Stage 1 - Retriever ì„¤ì •: Similarity (ìœ ì‚¬ë„)")
        print(f"   - k={RETRIEVAL_K}")
        dense_retriever = vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={"k": RETRIEVAL_K}
        )

    # Re-ranker ì„¤ì •
    stage_num = 2 if USE_HYBRID_SEARCH else 2
    if USE_RERANKER:
        print(f"ğŸ” Stage {stage_num} - Re-ranker í™œì„±í™”")
        print(f"   - ëª¨ë¸: {RERANKER_MODEL}")
        print(f"   - ìµœì¢… ë¬¸ì„œ ìˆ˜: {RERANKER_TOP_K}")
        if USE_HYBRID_SEARCH:
            print(f"   - íŒŒì´í”„ë¼ì¸: BM25+FAISS({BM25_TOP_K}+{DENSE_TOP_K}ê°œ) â†’ RRF({RRF_TOP_K}ê°œ) â†’ Re-rank({RERANKER_TOP_K}ê°œ)")
        else:
            print(f"   - íŒŒì´í”„ë¼ì¸: FAISS({MMR_K if USE_MMR else RETRIEVAL_K}ê°œ) â†’ Re-rank({RERANKER_TOP_K}ê°œ)")

    # QA ì²´ì¸ ìƒì„± (LCEL ë°©ì‹)
    def format_docs(docs):
        return "\n\n".join(doc.page_content for doc in docs)

    # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ + Re-ranker íŒŒì´í”„ë¼ì¸
    if USE_HYBRID_SEARCH:
        def hybrid_retrieve_and_rerank(query: str):
            """Hybrid Search (BM25 + FAISS) + Re-ranker íŒŒì´í”„ë¼ì¸"""
            # Stage 1a: BM25 ê²€ìƒ‰
            bm25_docs = bm25_retriever.invoke(query, top_k=BM25_TOP_K)

            # Stage 1b: FAISS Dense ê²€ìƒ‰
            dense_docs = dense_retriever.invoke(query)

            # Stage 1c: RRF ìœµí•©
            fused_docs = reciprocal_rank_fusion(
                bm25_docs, dense_docs,
                top_k=RRF_TOP_K,
                k=RRF_CONSTANT
            )

            # Stage 2: Re-ranking (ì˜µì…˜)
            if USE_RERANKER:
                final_docs = rerank_documents(query, fused_docs, top_k=RERANKER_TOP_K)
            else:
                final_docs = fused_docs

            return final_docs

        qa_chain = (
            {"context": RunnableLambda(hybrid_retrieve_and_rerank) | RunnableLambda(format_docs), "question": RunnablePassthrough()}
            | prompt
            | llm
            | StrOutputParser()
        )
        retriever = None  # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œ ë‹¨ì¼ retrieverëŠ” ì‚¬ìš© ì•ˆ í•¨

    # Re-rankerë§Œ ì‚¬ìš© (í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì—†ìŒ)
    elif USE_RERANKER:
        def retrieve_and_rerank(query: str):
            """Dense Retriever + Re-ranker íŒŒì´í”„ë¼ì¸"""
            # Stage 1: FAISS ê²€ìƒ‰
            docs = dense_retriever.invoke(query)
            # Stage 2: Cross-Encoder Re-ranking
            reranked_docs = rerank_documents(query, docs, top_k=RERANKER_TOP_K)
            return reranked_docs

        qa_chain = (
            {"context": RunnableLambda(retrieve_and_rerank) | RunnableLambda(format_docs), "question": RunnablePassthrough()}
            | prompt
            | llm
            | StrOutputParser()
        )
        retriever = dense_retriever

    # ê¸°ë³¸ Dense Retrieverë§Œ ì‚¬ìš©
    else:
        qa_chain = (
            {"context": dense_retriever | RunnableLambda(format_docs), "question": RunnablePassthrough()}
            | prompt
            | llm
            | StrOutputParser()
        )
        retriever = dense_retriever

    print(f"âœ… QA ì²´ì¸ ì„¤ì • ì™„ë£Œ")

    return retriever, qa_chain, bm25_retriever if USE_HYBRID_SEARCH else None


def is_exit_command(user_input: str) -> bool:
    """
    ì¢…ë£Œ ëª…ë ¹ì–´ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤.

    Args:
        user_input: ì‚¬ìš©ì ì…ë ¥

    Returns:
        bool: ì¢…ë£Œ ëª…ë ¹ì–´ ì—¬ë¶€
    """
    exit_keywords = ['ì¢…ë£Œ', 'ë', 'stop', 'quit', 'exit', 'finish']
    return user_input.strip().lower() in exit_keywords


def format_source_documents(source_docs):
    """
    ì¶œì²˜ ë¬¸ì„œë¥¼ í¬ë§·íŒ…í•©ë‹ˆë‹¤.

    Args:
        source_docs: ì¶œì²˜ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸

    Returns:
        str: í¬ë§·íŒ…ëœ ì¶œì²˜ ì •ë³´
    """
    if not source_docs:
        return "ì¶œì²˜ ì •ë³´ ì—†ìŒ"

    sources = []
    for i, doc in enumerate(source_docs, 1):
        source = doc.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')
        page = doc.metadata.get('page', None)

        if page is not None:
            sources.append(f"  [{i}] {source} (í˜ì´ì§€ {page + 1})")
        else:
            sources.append(f"  [{i}] {source}")

    return "\n".join(sources)


def run_query_loop(retriever, qa_chain, bm25_retriever=None):
    """
    ì‚¬ìš©ì ì§ˆì˜ë¥¼ ë°›ì•„ ì²˜ë¦¬í•˜ëŠ” ë©”ì¸ ë£¨í”„ì…ë‹ˆë‹¤.

    Args:
        retriever: ë¬¸ì„œ ê²€ìƒ‰ê¸° (Dense retriever, í•˜ì´ë¸Œë¦¬ë“œ ì‹œ None)
        qa_chain: QA ì²´ì¸
        bm25_retriever: BM25 ê²€ìƒ‰ê¸° (í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œ ì‚¬ìš©)
    """
    print("\n" + "=" * 60)
    print("ğŸ’¬ ë¬¸ì„œ Q&A ì‹œìŠ¤í…œì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!")
    print("=" * 60)
    print("â„¹ï¸  ì¢…ë£Œí•˜ë ¤ë©´ 'ì¢…ë£Œ', 'ë', 'stop', 'quit', 'finish' ì¤‘ í•˜ë‚˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    print("=" * 60 + "\n")

    while True:
        try:
            # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
            user_question = input("ğŸ¤” ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()

            # ë¹ˆ ì…ë ¥ ì²˜ë¦¬
            if not user_question:
                print("âš ï¸  ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.\n")
                continue

            # ì¢…ë£Œ ëª…ë ¹ì–´ í™•ì¸
            if is_exit_command(user_question):
                print("\nğŸ‘‹ ë¬¸ì„œ Q&A ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!")
                break

            # ì§ˆì˜ ì²˜ë¦¬
            print("\nğŸ” ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„± ì¤‘...")

            # ë‹µë³€ ìƒì„±
            answer = qa_chain.invoke(user_question)

            # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ (ì¶œì²˜ í‘œì‹œìš©)
            if USE_HYBRID_SEARCH:
                # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: BM25 + FAISS + RRF
                bm25_docs = bm25_retriever.invoke(user_question, top_k=BM25_TOP_K)
                dense_docs = retriever.invoke(user_question) if retriever else []
                source_docs = reciprocal_rank_fusion(
                    bm25_docs, dense_docs,
                    top_k=RRF_TOP_K,
                    k=RRF_CONSTANT
                )
                if USE_RERANKER:
                    source_docs = rerank_documents(user_question, source_docs, top_k=RERANKER_TOP_K)
            elif USE_RERANKER:
                # Re-rankerë§Œ ì‚¬ìš©
                source_docs = retriever.invoke(user_question)
                source_docs = rerank_documents(user_question, source_docs, top_k=RERANKER_TOP_K)
            else:
                # ê¸°ë³¸ Dense retriever
                source_docs = retriever.invoke(user_question)

            # ë‹µë³€ ì¶œë ¥
            print("\n" + "=" * 60)
            print("ğŸ“ ë‹µë³€:")
            print("=" * 60)
            print(answer)

            # ì¶œì²˜ ë¬¸ì„œ ì¶œë ¥
            if source_docs:
                print("\n" + "-" * 60)
                print("ğŸ“š ì°¸ê³  ë¬¸ì„œ:")
                print("-" * 60)
                print(format_source_documents(source_docs))

            print("\n" + "=" * 60 + "\n")

        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            print("ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\n")


def main():
    """
    ë©”ì¸ í•¨ìˆ˜: ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ -> QA ì²´ì¸ ì„¤ì • -> ì§ˆì˜ ë£¨í”„ ì‹¤í–‰
    """
    print("=" * 60)
    print("ğŸ“š ë¬¸ì„œ ì§ˆì˜ í”„ë¡œê·¸ë¨ ì‹œì‘")
    print("=" * 60)

    # 1. ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
    vectorstore = load_vectorstore()

    # 2. BM25 ê²€ìƒ‰ê¸° ìƒì„± (í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‚¬ìš© ì‹œ)
    bm25_retriever = None
    if USE_HYBRID_SEARCH:
        print(f"\nğŸ”§ BM25 ê²€ìƒ‰ê¸° ìƒì„± ì¤‘...")
        bm25_retriever = create_bm25_retriever(vectorstore)

    # 3. QA ì²´ì¸ ì„¤ì •
    retriever, qa_chain, bm25_ret = setup_qa_chain(vectorstore, bm25_retriever)
    if bm25_ret:
        bm25_retriever = bm25_ret

    # 4. ì§ˆì˜ ë£¨í”„ ì‹¤í–‰
    run_query_loop(retriever, qa_chain, bm25_retriever)


if __name__ == "__main__":
    main()
